b'The Link Prediction Problem for Social Networks(cid:3)David Liben-NowellyJon KleinbergzLaboratory for Computer ScienceDepartment of Computer ScienceMassachusetts Institute of TechnologyCambridge, MA 02139 USAdln@theory.lcs.mit.eduCornell UniversityIthaca, NY 14853 USAkleinber@cs.cornell.eduJanuary 8, 2004AbstractGiven a snapshot of a social network, can we infer which new interactions among its members\nare likely to occur in the near future? We formalize this question as the link prediction problem,\nand develop approaches to link prediction based on measures for analyzing the \\proximity" of\nnodes in a network. Experiments on large co-authorship networks suggest that information\nabout future interactions can be extracted from network topology alone, and that fairly subtle\nmeasures for detecting node proximity can outperform more direct measures.1 IntroductionAs part of the recent surge of research on large, complex networks and their properties, a consid-\nerable amount of attention has been devoted to the computational analysis of social networks|\nstructures whose nodes represent people or other entities embedded in a social context, and whose\nedges represent interaction, collaboration, or in(cid:13)uence between entities. Natural examples of social\nnetworks include the set of all scientists in a particular discipline, with edges joining pairs who\nhave co-authored papers; the set of all employees in a large company, with edges joining pairs\nworking on a common project; or a collection of business leaders, with edges joining pairs who\nhave served together on a corporate board of directors. The availability of large, detailed datasets\nencoding such networks has stimulated extensive study of their basic properties, and the identi-\n(cid:12)cation of recurring structural features. (See, for example, the work of Watts and Strogatz [28],\nWatts [27], Grossman [9], Newman [19], and Adamic and Adar [1], or, for a thorough recent survey,\nNewman [20].)Social networks are highly dynamic objects; they grow and change quickly over time through\nthe addition of new edges, signifying the appearance of new interactions in the underlying social\nstructure. Understanding the mechanisms by which they evolve is a fundamental question that\nis still not well understood, and it forms the motivation for our work here. We de(cid:12)ne and study\na basic computational problem underlying social network evolution, the link prediction problem:(cid:3)An abbreviated version of this paper appears in Proceedings of the Twelfth Annual ACM International Conferenceon Information and Knowledge Management (CIKM 03), November 2003, pp. 556{559.ySupported in part by an NSF Graduate Research Fellowship.\nzSupported in part by a David and Lucile Packard Foundation Fellowship and NSF ITR Grant IIS-0081334.1\x0cGiven a snapshot of a social network at time t, we seek to accurately predict the edges that will be\nadded to the network during the interval from time t to a given future time t0.In e(cid:11)ect, the link prediction problem asks: to what extent can the evolution of a social network\nbe modeled using features intrinsic to the network itself ? Consider a co-authorship network among\nscientists, for example. There are many reasons, exogenous to the network, why two scientists who\nhave never written a paper together will do so in the next few years: for example, they may happen\nto become geographically close when one of them changes institutions. Such collaborations can be\nhard to predict. But one also senses that a large number of new collaborations are hinted at by\nthe topology of the network: two scientists who are \\close" in the network will have colleagues in\ncommon, and will travel in similar circles; this suggests that they themselves are more likely to\ncollaborate in the near future. Our goal is to make this intuitive notion precise, and to understand\nwhich measures of \\proximity" in a network lead to the most accurate link predictions. We (cid:12)nd\nthat a number of proximity measures lead to predictions that outperform chance by factors of 40 to\n50, indicating that the network topology does indeed contain latent information from which to infer\nfuture interactions. Moreover, certain fairly subtle measures|involving in(cid:12)nite sums over paths in\nthe network|often outperform more direct measures, such as shortest-path distances and numbers\nof shared neighbors.We believe that a primary contribution of the present paper is in the area of network evolution\nmodels. While there has been a proliferation of such models in recent years|see, for example, the\nwork of Jin et al. [11], Barabasi et al. [2], and Davidsen et al. [5] for recent work on collaboration\nnetworks, or the survey of Newman [20]|they have generally been evaluated only by asking whether\nthey reproduce certain global structural features observed in real networks. As a result, it has been\ndi(cid:14)cult to evaluate and compare di(cid:11)erent approaches on a principled footing. Link prediction, on\nthe other hand, o(cid:11)ers a very natural basis for such evaluations: a network model is useful to the\nextent that it can support meaningful inferences from observed network data. One sees a related\napproach in recent work of Newman [17], who considers the correlation between certain network\ngrowth models and data on the appearance of edges of co-authorship networks.In addition to its role as a basic question in social network evolution, the link prediction problem\ncould be relevant to a number of interesting current applications of social networks. Increasingly, for\nexample, researchers in arti(cid:12)cial intelligence and data mining have argued that a large organization,\nsuch as a company, can bene(cid:12)t from the interactions within the informal social network among its\nmembers; these serve to supplement the o(cid:14)cial hierarchy imposed by the organization itself [13, 23].\nE(cid:11)ective methods for link prediction could be used to analyze such a social network, and suggest\npromising interactions or collaborations that have not yet been utilized within the organization.\nIn a di(cid:11)erent vein, research in security has recently begun to emphasize the role of social network\nanalysis, largely motivated by the problem of monitoring terrorist networks; link prediction in this\ncontext allows one to conjecture that particular individuals are working together even though their\ninteraction has not been directly observed [14].The link prediction problem is also related to the problem of inferring missing links from an\nobserved network:\nin a number of domains, one constructs a network of interactions based on\nobservable data and then tries to infer additional links that, while not directly visible, are likely\nto exist [8, 22, 26]. This line of work di(cid:11)ers from our problem formulation in that it works with\na static snapshot of a network, rather than considering network evolution; it also tends to take\ninto account speci(cid:12)c attributes of the nodes in the network, rather than evaluating the power of\nprediction methods based purely on the graph structure.We now turn to a description of our experimental setup, in Section 2. Our primary focus is on2\x0ctraining periodauthors papers\n5816\n6700\n3287\n10254\n94985343\n5469\n2122\n5414\n5241edges\n41852\n19881\n5724\n17806\n15842authors1561\n1253\n486\n1790\n1438Core\njEold j\n6178\n1899\n519\n6654\n2311jEnew j\n5751\n1150\n400\n3294\n1576astro-phcond-matgr-qchep-phhep-thFigure 1: The (cid:12)ve sections of the arXiv from which co-authorship networks were constructed:\nastro-ph (astrophysics), cond-mat (condensed matter), gr-qc (general relativity and quantum\ncosmology), hep-ph (high energy physics|phenomenology), and hep-th (high energy physics|\ntheory). The set Core is the subset of the authors who have written at least (cid:20)training = 3 papers\nduring the training period and (cid:20)test = 3 papers during the test period. The sets Eold and Enew\ndenote edges between Core authors which (cid:12)rst appear during the training and test periods, respec-\ntively.understanding the relative e(cid:11)ectiveness of network proximity measures adapted from techniques\nin graph theory, computer science, and the social sciences, and we review a large number of such\ntechniques in Section 3. Finally, we discuss the results of our experiments in Section 4.2 Data and Experimental Setup0 < t1 < t01, and give an algorithm access to the network G[t0; t01] as the test interval.Suppose we have a social network G = hV; Ei in which each edge e = hu; vi 2 E represents\nan interaction between u and v that took place at a particular time t(e). We record multiple\ninteractions between u and v as parallel edges, with potentially di(cid:11)erent time-stamps. For two\ntimes t < t0, let G[t; t0] denote the subgraph of G consisting of all edges with a time-stamp between\nt and t0. Here, then, is a concrete formulation of the link prediction problem. We choose four times\nt0 < t0\n0]; it must then output a list\nof edges, not present in G[t0; t0\n1]. We refer to\n[t0; t00] as the training interval and [t1; t0\nOf course, social networks grow through the addition of nodes as well as edges, and it is not\nsensible to seek predictions for edges whose endpoints are not present in the training interval. Thus,\nin evaluating link prediction methods, we will generally use two parameters (cid:20)training and (cid:20)test (each\nset to 3 below), and de(cid:12)ne the set Core to be all nodes incident to at least (cid:20)training edges in G[t0; t0\n0]\nand at least (cid:20)test edges in G[t1; t0\n1]. We will then evaluate how accurately the new edges between\nelements of Core can be predicted.0], that are predicted to appear in the network G[t1; t0We now describe our experimental setup more speci(cid:12)cally. We work with (cid:12)ve co-authorship\nnetworks G, obtained from the author lists of papers at (cid:12)ve sections of the physics e-Print arXiv,\nwww.arxiv.org. (See Figure 1 for statistics on the size of each of these (cid:12)ve networks.) Some\nheuristics were used to deal with occasional syntactic anomalies; and authors were identi(cid:12)ed by\n(cid:12)rst initial and last name, a process that introduces a small amount of noise due to multiple authors\nwith the same identi(cid:12)er [18]. The errors introduced by this process appear to be minor.Now consider any one of these (cid:12)ve graphs. We de(cid:12)ne the training interval to be the three years\n[1994; 1996], and the test interval to be [1997; 1999]. We denote the subgraph G[1994; 1996] on the\ntraining interval by Gcollab := hA; Eold i, and use Enew to denote the set of edges hu; vi such that\nu; v 2 A, and u; v co-author a paper during the test interval but not the training interval|these\nare the new interactions we are seeking to predict.3\x0c(negated) length of shortest path between x and y\nj(cid:0)(x) \\ (cid:0)(y)j\nj(cid:0)(x)\\(cid:0)(y)j\nj(cid:0)(x)[(cid:0)(y)jgraph distance\ncommon neighbors\nJaccard s coe(cid:14)cient\nAdamic/Adar\npreferential attachmentKatz(cid:12)1log j(cid:0)(z)jj(cid:0)(x)j (cid:1) j(cid:0)(y)jPz2(cid:0)(x)\\(cid:0)(y)\n =1 (cid:12)  (cid:1) jpathsh i\nP1\nx;yjwhere pathsh ix;y := fpaths of length exactly   from x to ygweighted: pathsh1i\nunweighted: pathsh1ix;y := number of collaborations between x; y.x;y := 1 i(cid:11) x and y collaborate.hitting timestationary-normedcommute timestationary-normed(cid:0)Hx;y\n(cid:0)Hx;y (cid:1) (cid:25)y\n(cid:0)(Hx;y + Hy;x)\n(cid:0)(Hx;y (cid:1) (cid:25)y + Hy;x (cid:1) (cid:25)x)rooted PageRank(cid:11)where Hx;y\n(cid:25)y:= expected time for random walk from x to reach y\n:= stationary distribution weight of y(proportion of time the random walk is at node y)\nstationary distribution weight of y under the following random walk:with probability (cid:11), jump to x.\nwith probability 1 (cid:0) (cid:11), go to random neighbor of current node.SimRank(cid:13)( 1(cid:13) (cid:1)a2(cid:0)(x) \x00b2(cid:0)(y) score(a;b)j(cid:0)(x)j(cid:1)j(cid:0)(y)jif x = yotherwiseFigure 2: Values for score(x; y) under various predictors; each predicts pairs hx; yi in descending\norder of score(x; y). The set (cid:0)(x) consists of the neighbors of the node x in Gcollab .Evaluating a link predictor. Each link predictor p that we consider outputs a ranked list Lp of\npairs in A (cid:2) A (cid:0) Eold ; these are predicted new collaborations, in decreasing order of con(cid:12)dence. For\nour evaluation, we focus on the set Core, so we de(cid:12)ne E(cid:3)\nnew j.\nOur performance measure for predictor p is then determined as follows: from the ranked list Lp, we\ntake the (cid:12)rst n pairs in Core (cid:2) Core, and determine the size of the intersection of this set of pairs\nwith the set E(cid:3)new := Enew \\ (Core (cid:2) Core) and n := jE(cid:3)new .3 Methods for Link PredictionIn this section, we survey an array of methods for link prediction. All the methods assign a\nconnection weight score(x; y) to pairs of nodes hx; yi, based on the input graph Gcollab , and then\nproduce a ranked list in decreasing order of score(x; y). Thus, they can be viewed as computing a\nmeasure of proximity or \\similarity" between nodes x and y, relative to the network topology. In\ngeneral, the methods are adapted from techniques used in graph theory and social network analysis;\nin a number of cases, these techniques were not designed to measure node-to-node similarity, and\nhence need to be modi(cid:12)ed for this purpose. Figure 2 summarizes most of these measures; below we4\x00\n\x0cdiscuss them in more detail. We note that some of these measures are designed only for connected\ngraphs; since each graph Gcollab that we consider has a giant component|a single component\ncontaining most of the nodes|it is natural to restrict the predictions for these measures to this\ncomponent.Perhaps the most basic approach is to rank pairs hx; yi by the length of their shortest path in\nGcollab . Such a measure follows the notion that collaboration networks are \\small worlds," in which\nindividuals are related through short chains [18]. (In keeping with the notion that we rank pairs\nin decreasing order of score(x; y), we de(cid:12)ne score(x; y) here to be the negative of the shortest path\nlength.) Pairs with shortest-path distance equal to 1 are joined by an edge in Gcollab , and hence\nthey belong to the training edge set Eold . For all of our graphs Gcollab , there are well more than n\npairs at shortest-path distance two, so our shortest-path predictor simply selects a random subset\nof these distance-two pairs.Methods based on node neighborhoods. For a node x, let (cid:0)(x) denote the set of neighbors\nof x in Gcollab . A number of approaches are based on the idea that two nodes x and y are more\nlikely to form a link in the future if their sets of neighbors (cid:0)(x) and (cid:0)(y) have large overlap; this\nfollows the natural intuition that such nodes x and y represent authors with many colleagues in\ncommon, and hence are more likely to come into contact themselves. Jin et al. [11] and Davidsen\net al. [5] have de(cid:12)ned abstract models for network growth using this principle, in which an edge\nhx; yi is more likely to form if edges hx; zi and hz; yi are already present for some z.(cid:15) Common neighbors. The most direct implementation of this idea for link prediction is to de(cid:12)ne\nscore(x; y) := j(cid:0)(x) \\ (cid:0)(y)j, the number of neighbors that x and y have in common. Newman [17]\nhas computed this quantity in the context of collaboration networks, verifying a correlation between\nthe number of common neighbors of x and y at time t, and the probability that they will collaborate\nin the future.(cid:15) Jaccard s coe(cid:14)cient and Adamic/Adar. The Jaccard coe(cid:14)cient|a commonly used similarity\nmetric in information retrieval [24]|measures the probability that both x and y have a feature f ,\nfor a randomly selected feature f that either x or y has. If we take \\features" here to be neighbors\nin Gcollab , this leads to the measure score(x; y) := j(cid:0)(x) \\ (cid:0)(y)j=j(cid:0)(x) [ (cid:0)(y)j. Adamic and Adar [1]\nconsider a related measure, in the context of deciding when two personal home pages are strongly\n\\related." To do this, they compute features of the pages, and de(cid:12)ne the similarity between two\npages to be1log(frequency(z)):z : feature shared by x; yXThis re(cid:12)nes the simple counting of common features by weighting rarer features more heavily. This1log j(cid:0)(z)j .suggests the measure score(x; y) :=Pz2(cid:0)(x)\\(cid:0)(y)(cid:15) Preferential attachment has received considerable attention as a model of the growth of net-\nworks [16]. The basic premise is that the probability that a new edge involves node x is proportional\nto j(cid:0)(x)j, the current number of neighbors of x. Newman [17] and Barabasi et al. [2] have further\nproposed, on the basis of empirical evidence, that the probability of co-authorship of x and y is\ncorrelated with the product of the number of collaborators of x and y. This corresponds to the\nmeasure score(x; y) := j(cid:0)(x)j (cid:1) j(cid:0)(y)j.Methods based on the ensemble of all paths. A number of methods re(cid:12)ne the notion of\nshortest-path distance by implicitly considering the ensemble of all paths between two nodes.5\x0c(cid:15) Katz [12] de(cid:12)nes a measure that directly sums over this collection of paths, exponentiallydamped by length to count short paths more heavily. This leads to the measurescore(x; y) :=(cid:12)  (cid:1) jpathsh ix;yj;1X =1where pathsh i\nx;y is the set of all length-  paths from x to y. (A very small (cid:12) yields predictions much\nlike common neighbors, since paths of length three or more contribute very little to the summation.)\nOne can verify that the matrix of scores is given by (I (cid:0) (cid:12)M )(cid:0)1 (cid:0) I, where M is the adjacency\nmatrix of the graph. We consider two variants of this Katz measure: (1) unweighted, in which\npathsh1i\nx;y is\nthe number of times that x and y have collaborated.x;y = 1 if x and y have collaborated and 0 otherwise, and (2) weighted, in which pathsh1i(cid:15) Hitting time, PageRank, and variants. A random walk on Gcollab starts at a node x, and\niteratively moves to a neighbor of x chosen uniformly at random. The hitting time Hx;y from x to y\nis the expected number of steps required for a random walk starting at x to reach y. Since the hitting\ntime is not in general symmetric, it is also natural to consider the commute time Cx;y := Hx;y +Hy;x.\nBoth of these measures serve as natural proximity measures, and hence (negated) can be used as\nscore(x; y).One di(cid:14)culty with hitting time as a measure of proximity is that Hx;y is quite small whenever y\nis a node with a large stationary probability (cid:25)y, regardless of the identity of x. To counterbalance this\nphenomenon, we also consider normalized versions of the hitting and commute times, by de(cid:12)ning\nscore(x; y) := (cid:0)Hx;y (cid:1) (cid:25)y or score(x; y) := (cid:0)(Hx;y (cid:1) (cid:25)y + Hy;x (cid:1) (cid:25)x).Another di(cid:14)culty with these measures is their sensitive dependence to parts of the graph far\naway from x and y, even when x and y are connected by very short paths. A way of counteracting\nthis is to allow the random walk from x to y to periodically \\reset," returning to x with a (cid:12)xed\nprobability (cid:11) at each step; in this way, distant parts of the graph will almost never be explored.\nRandom resets form the basis of the PageRank measure for Web pages [3], and we can adapt it\nfor link prediction as follows: De(cid:12)ne score(x; y) under the rooted PageRank measure to be the\nstationary probability of y in a random walk that returns to x with probability (cid:11) each step, moving\nto a random neighbor with probability 1 (cid:0) (cid:11).(cid:15) SimRank [10] is a (cid:12)xed point of the following recursive de(cid:12)nition: two nodes are similar to\nthe extent that they are joined to similar neighbors. Numerically, this is speci(cid:12)ed by de(cid:12)ning\nsimilarity(x; x) := 1 andsimilarity(x; y) := (cid:13) (cid:1) Pa2(cid:0)(x)Pb2(cid:0)(y) similarity(a; b)j(cid:0)(x)j (cid:1) j(cid:0)(y)jfor some (cid:13) 2 [0; 1]. We then de(cid:12)ne score(x; y) := similarity(x; y). SimRank can also be interpreted\nin terms of a random walk on the collaboration graph: it is the expected value of (cid:13) , where   is a\nrandom variable giving the time at which random walks started from x and y (cid:12)rst meet.Higher-level approaches. We now discuss three \\meta-approaches" that can be used in con-\njunction with any of the methods discussed above.(cid:15) Low-rank approximation. Since the adjacency matrix M can be used to represent the graph\nGcollab , all of our link prediction methods have an equivalent formulation in terms of this matrix M .\nIn some cases, this was noted explicitly above (for example in the case of the Katz similarity score);\nbut in many cases the matrix formulation is quite natural. For example, the common neighbors6\x0cmethod consists simply of mapping each node x to its row r(x) in M , and then de(cid:12)ning score(x; y)\nto be the inner product of the rows r(x) and r(y).A common general technique when analyzing the structure of a large matrix M is to choose\na relatively small number k and compute the rank-k matrix Mk that best approximates M with\nrespect to any of a number of standard matrix norms. This can be done e(cid:14)ciently using the\nsingular value decomposition, and it forms the core of methods like latent semantic analysis in\ninformation retrieval [6]. Intuitively, working with Mk rather than M can be viewed as a type of\n\\noise-reduction" technique that generates most of the structure in the matrix but with a greatly\nsimpli(cid:12)ed representation.In our experiments, we investigate three applications of low-rank approximation: (i) ranking by\nthe Katz measure, in which we use Mk rather than M in the underlying formula; (ii) ranking by\ncommon neighbors, in which we score by inner products of rows in Mk rather than M ; and|most\nsimply of all|(iii) de(cid:12)ning score(x; y) to be the hx; yi entry in the matrix Mk.(cid:15) Unseen bigrams. Link prediction is akin to the problem of estimating frequencies for unseen\nbigrams in language modeling|pairs of words that co-occur in a test corpus, but not in the corre-\nsponding training corpus (see, e.g., the work of Essen and Steinbiss [7]). Following ideas proposed\nin that literature [15, for example], we can augment our estimates for score(x; y) using values of\nscore(z; y) for nodes z that are \\similar" to x. Speci(cid:12)cally, we adapt this to the link prediction\nproblem as follows. Suppose we have values score(x; y) computed under one of the measures above.\nLet Sh(cid:14)i\nx denote the (cid:14) nodes most related to x under score(x; (cid:1)), for a parameter (cid:14) 2 Z+. We then\nde(cid:12)ne enhanced scores in terms of the nodes in this set:score(cid:3)unweighted (x; y)score(cid:3)weighted (x; y)fz : z 2 (cid:0)(y) \\ Sh(cid:14)i:= (cid:12)(cid:12)(cid:12)\n:= Xz2(cid:0)(y)\\Sx g(cid:12)(cid:12)(cid:12)score(x; z):h(cid:14)i\nx(cid:15) Clustering. One might seek to improve on the quality of a predictor by deleting the more\n\\tenuous" edges in Gcollab through a clustering procedure, and then running the predictor on the\nresulting \\cleaned-up" subgraph. Consider a measure computing values for score(x; y). We compute\nscore(u; v) for all edges in Eold , and delete the (1 (cid:0) (cid:26)) fraction of these edges for which the score is\nlowest. We now recompute score(x; y) for all pairs hx; yi on this subgraph; in this way we determine\nnode proximities using only edges for which the proximity measure itself has the most con(cid:12)dence.4 Results and DiscussionAs discussed in Section 1, many collaborations form (or fail to form) for reasons outside the scope\nof the network; thus the raw performance of our predictors is relatively low. To more meaningfully\nrepresent predictor quality, we use as our baseline a random predictor which simply randomly selects\npairs of authors who did not collaborate in the training interval. A random prediction is correct\nwith probability between 0.15% (cond-mat) and 0.48% (astro-ph). Figures 3 and 4 show each\npredictor s performance on each arXiv section, in terms of the factor improvement over random.\nFigures 5, 6, and 7 show the average relative performance of several di(cid:11)erent predictors versus\nthree baseline predictors|the random predictor, the graph distance predictor, and the common\nneighbors predictor. There is no single clear winner among the techniques, but we see that a\nnumber of methods signi(cid:12)cantly outperform the random predictor, suggesting that there is indeed\nuseful information contained in the network topology alone. The Katz measure and its variants\nbased on clustering and low-rank approximation perform consistently well; on three of the (cid:12)ve7\x0cpredictor\nprobability that a random prediction is correct\ngraph distance (all distance-two pairs)\ncommon neighbors\npreferential attachment\nAdamic/Adar\nJaccard\nSimRank\nhitting time\nhitting time|normed by stationary distribution\ncommute time\ncommute time|normed by stationary distribution\nrooted PageRank(cid:13) = 0:8Katz (weighted)Katz (unweighted)astro-ph\n0.475%\n9.6\n18.0\n4.7\n16.8\n16.4\n14.6\n6.5\n5.3\n5.2\n5.3\n10.8\n13.8\n16.6\n17.1\n16.8\n3.0\n13.4\n14.5\n10.9\n16.8\n16.8cond-matgr-qchep-phhep-th\n0.147% 0.341% 0.207% 0.153%\n29.2\n47.2\n7.5\n50.5\n41.7\n41.7\n13.4\n21.3\n23.4\n16.3\n29.2\n41.3\n42.6\n46.8\n46.8\n12.9\n52.2\n51.8\n48.0\n49.7\n49.721.4\n27.2\n7.6\n30.1\n19.9\n22.8\n25.0\n11.0\n33.1\n11.0\n33.1\n35.3\n27.2\n25.0\n24.3\n19.9\n30.1\n30.1\n37.5\n37.5\n37.525.3\n41.1\n6.1\n54.8\n42.3\n39.3\n23.8\n23.8\n15.5\n16.1\n28.0\n39.9\n41.1\n42.3\n41.1\n21.4\n54.8\n54.2\n41.7\n41.7\n41.712.2\n27.0\n15.2\n33.3\n27.7\n26.1\n3.8\n11.3\n17.1\n11.3\n18.7\n24.6\n27.6\n29.9\n30.7\n2.4\n24.0\n32.6\n18.7\n24.2\n24.9(cid:11) = 0:01\n(cid:11) = 0:05\n(cid:11) = 0:15\n(cid:11) = 0:30\n(cid:11) = 0:50\n(cid:12) = 0:05\n(cid:12) = 0:005\n(cid:12) = 0:0005\n(cid:12) = 0:05\n(cid:12) = 0:005\n(cid:12) = 0:0005Figure 3: Performance of various predictors on the link prediction task de(cid:12)ned in Section 2. For each\npredictor and each arXiv section, the given number speci(cid:12)es the factor improvement over random\nprediction. Two predictors in particular are used as baselines for comparison: graph distance and\ncommon neighbors (see Section 3 for de(cid:12)nitions of these). Italicized entries have performance at\nleast as good as the graph distance predictor; bold entries are at least as good as the common\nneighbors predictor. See also Figure 4.8\x0cpredictor\nprobability that a random prediction is correct\ngraph distance (all distance-two pairs)\ncommon neighbors\nLow-rank approximation:\nInner productLow-rank approximation:\nMatrix entryLow-rank approximation:\nKatz ((cid:12) = 0:005)unseen bigrams\n(weighted)unseen bigrams\n(unweighted)clustering:\nKatz ((cid:12)1 = 0:001; (cid:12)2 = 0:1)astro-ph\n0.475%\n9.6\n18.015.2\n14.6\n13.0\n10.1\n8.8\n6.9\n8.2\n15.4\n13.8\n9.1\n8.8\n6.9\n11.4\n15.4\n13.1\n9.2\n7.0\n0.4\n13.5\n13.4\n16.9\n16.5\n14.2\n15.3\n13.1\n10.3\n7.4\n12.0\n4.6\n3.3cond-matgr-qchep-phhep-th\n0.147% 0.341% 0.207% 0.153%\n29.2\n47.212.2\n27.021.4\n27.225.3\n41.154.2\n47.1\n44.7\n21.4\n15.5\n6.0\n16.7\n36.3\n46.5\n21.4\n15.5\n6.0\n27.4\n42.3\n45.3\n21.4\n15.5\n6.0\n36.9\n39.9\n38.1\n39.9\n40.5\n39.3\n36.9\n29.8\n37.5\n46.5\n34.5\n27.429.4\n29.4\n27.2\n31.6\n42.6\n44.9\n6.6\n8.1\n16.9\n26.5\n39.7\n44.9\n30.1\n11.0\n19.1\n27.2\n41.2\n44.930.1\n39.0\n25.0\n35.3\n27.9\n42.6\n32.4\n41.947.1\n47.1\n19.9\n20.634.9\n32.4\n30.8\n27.9\n19.6\n17.7\n18.6\n26.2\n28.1\n23.1\n20.0\n17.7\n27.1\n34.3\n32.3\n24.9\n19.7\n17.715.6\n18.6\n24.2\n24.8\n22.3\n22.1\n21.7\n12.233.0\n21.1\n21.2\n19.550.1\n47.2\n47.6\n35.5\n23.0\n14.6\n21.7\n37.6\n40.9\n34.2\n22.5\n14.6\n32.1\n38.8\n41.3\n35.1\n23.0\n14.647.2\n48.8\n51.3\n50.9\n39.7\n42.6\n38.0\n38.0\n38.0\n44.2\n35.9\n17.5rank = 1024\nrank = 256\nrank = 64\nrank = 16\nrank = 4\nrank = 1\nrank = 1024\nrank = 256\nrank = 64\nrank = 16\nrank = 4\nrank = 1\nrank = 1024\nrank = 256\nrank = 64\nrank = 16\nrank = 4\nrank = 1\ncommon neighbors, (cid:14) = 8\ncommon neighbors, (cid:14) = 16\nKatz ((cid:12) = 0:005), (cid:14) = 8\nKatz ((cid:12) = 0:005), (cid:14) = 16\ncommon neighbors, (cid:14) = 8\ncommon neighbors, (cid:14) = 16\nKatz ((cid:12) = 0:005), (cid:14) = 8\nKatz ((cid:12) = 0:005), (cid:14) = 16\n(cid:26) = 0:10\n(cid:26) = 0:15\n(cid:26) = 0:20\n(cid:26) = 0:25Figure 4: Performance of various meta-approaches on the link prediction task de(cid:12)ned in Section 2.\nAs before, for each predictor and each arXiv section, the given number speci(cid:12)es the factor improve-\nment over random prediction. See Figure 3.9\x0cs\nn\no\ni\nt\nc\ni\nd\ne\nr\np\nm\no\nd\nn\na\nrs\nu\ns\nr\ne\nvo\ni\nt\na\nre\nc\nn\na\nm\nr\no\nf\nr\ne\npe\nv\ni\nt\na\nl\ne\nR50403020100random predictorr\na\nd\nA\n/\nc\ni\nm\na\nd\nA(cid:3)\nz\nt\na\nK\nd\ne\nt\nh\ng\ni\ne\nw(cid:3)\ng\nn\ni\nr\ne\nt\ns\nu\nl\ncz\nt\na\nKs\nr\no\nb\nh\ng\ni\ne\nnn\no\nm\nm\no\nc(cid:3)\nk\nn\na\nR\ne\ng\na\nP\nd\ne\nt\no\no\nr(cid:3)\nt\nc\nu\nd\no\nr\npr\ne\nn\nn\nik\nn\na\nr\n-\nw\no\nld\nr\na\nc\nc\na\nJ(cid:3)\nsm\na\nr\ng\ni\nbn\ne\ne\ns\nn\nu(cid:3)\nk\nn\na\nR\nm\ni\nSe\nmi\ntg\nn\ni\nt\nt\ni\nhe\nc\nn\na\nt\ns\ni\ndh\np\na\nr\ngFigure 5: Relative average performance of various predictors versus random predictions. The value\nshown is the average ratio over the (cid:12)ve datasets of the given predictor s performance versus the\nrandom predictor s performance. The error bars indicate the minimum and maximum of this\nratio over the (cid:12)ve datasets. The parameters for the starred predictors are: (1) for weighted Katz,\n(cid:12) = 0:005; (2) for Katz clustering, (cid:12)1 = 0:001; (cid:26) = 0:15; (cid:12)2 = 0:1; (3) for low-rank inner product,\nrank = 256; (4) for rooted Pagerank, (cid:11) = 0:15; (5) for unseen bigrams, unweighted common\nneighbors with (cid:14) = 8; and (6) for SimRank, (cid:13) = 0:8.10\x0cr\no\nt\nc\ni\nd\ne\nr\npe\nc\nn\na\nt\ns\ni\ndh\np\na\nr\ngs\nu\ns\nr\ne\nvo\ni\nt\na\nre\nc\nn\na\nm\nr\no\nf\nr\ne\npe\nv\ni\nt\na\nl\ne\nR3.002.001.000graph distance predictorz\nt\na\nK\nd\ne\nt\nh\ng\ni\ne\nws\nr\no\nb\nh\ng\ni\ne\nnn\no\nm\nm\no\ncg\nn\ni\nr\ne\nt\ns\nu\nl\ncz\nt\na\nKk\nn\na\nR\ne\ng\na\nP\nd\ne\nt\no\no\nrd\nr\na\nc\nc\na\nJk\nn\na\nR\nm\ni\nSe\nmi\ntg\nn\ni\nt\nt\ni\nhsm\na\nr\ng\ni\nbn\ne\ne\ns\nn\nur\na\nd\nA\n/\nc\ni\nm\na\nd\nAt\nc\nu\nd\no\nr\npr\ne\nn\nn\nik\nn\na\nr\n-\nw\no\nlFigure 6: Relative average performance of various predictors versus the graph distance predictor.\nThe plotted value shows the average taken over the (cid:12)ve datasets of the ratio of the performance\nof the given predictor versus the graph distance predictor; the error bars indicate the range of this\nratio over the (cid:12)ve datasets. All parameter settings are as in Figure 5.11\x0cr\no\nt\nc\ni\nd\ne\nr\nps\nr\no\nb\nh\ng\ni\ne\nnn\no\nm\nm\no\ncs\nu\ns\nr\ne\nvo\ni\nt\na\nre\nc\nn\na\nm\nr\no\nf\nr\ne\npe\nv\ni\nt\na\nl\ne\nR2.001.000common neighbors predictorz\nt\na\nK\nd\ne\nt\nh\ng\ni\ne\nwk\nn\na\nR\ne\ng\na\nP\nd\ne\nt\no\no\nrd\nr\na\nc\nc\na\nJsm\na\nr\ng\ni\nbn\ne\ne\ns\nn\nuk\nn\na\nR\nm\ni\nSe\nmi\ntg\nn\ni\nt\nt\ni\nhe\nc\nn\na\nt\ns\ni\ndh\np\na\nr\ngr\na\nd\nA\n/\nc\ni\nm\na\nd\nAg\nn\ni\nr\ne\nt\ns\nu\nl\ncz\nt\na\nKt\nc\nu\nd\no\nr\npr\ne\nn\nn\nik\nn\na\nr\n-\nw\no\nlFigure 7: Relative average performance of various predictors versus the common neighbors predic-\ntor, as in Figure 6. Error bars display the range of the performance ratio of the given predictor\nversus common neighbors over the (cid:12)ve datasets; the displayed value gives the average ratio. Pa-\nrameter settings are as in Figure 5.12\x0cr\na\nd\nA\n/\nc\ni\nm\na\nd\nAg\nn\ni\nr\ne\nt\ns\nu\nl\ncz\nt\na\nK1150638\n1150s\nr\no\nb\nh\ng\ni\ne\nnn\no\nm\nm\no\nc520\n411\n1150e\nmi\ntg\nn\ni\nt\nt\ni\nh193\n182\n135\n1150t\nn\ne\ni\nc\n(cid:14)\ne\no\ncs\n \nd\nr\na\nc\nc\na\nJ442\n285\n506\n87\n1150z\nt\na\nK\nd\ne\nt\nh\ng\ni\ne\nw1011\n630\n494\n191\n414\n1150t\nc\nu\nd\no\nr\npr\ne\nn\nn\nik\nn\na\nr\n-\nw\no\nl905\n623\n467\n192\n382\n1013\n1150k\nn\na\nr\ne\ng\na\nP\nd\ne\nt\no\no\nr528\n347\n305\n247\n504\n488\n453\n1150sm\na\nr\ng\ni\nbn\ne\ne\ns\nn\nu486\n389\n489\n156\n458\n474\n448\n461\n423\n1150k\nn\na\nR\nm\ni\nS372\n245\n332\n130\n845\n344\n320\n678\n1150Adamic/Adar\nKatz clustering\ncommon neighbors\nhitting time\nJaccard s coe(cid:14)cient\nweighted Katz\nlow-rank inner product\nrooted Pagerank\nSimRank\nunseen bigramsFigure 8: The number of common predictions made by various predictors on the cond-mat dataset,\nout of 1150 predictions. Parameter settings are as in Figure 5.arXiv sections, a variant of Katz achieves the best performance. Some of the very simple measures\nalso perform surprisingly well, including common neighbors and the Adamic/Adar measure.Similarities among the predictors and the datasets. Not surprisingly, there is signi(cid:12)cant\noverlap in the predictions made by the various methods.\nIn Figure 8, we show the number of\ncommon predictions made by ten of the most successful measures on the cond-mat graph. We\nsee that Katz, low-rank inner product, and Adamic/Adar are quite similar in their predictions,\nas are (to a somewhat lesser extent) rooted PageRank, SimRank, and Jaccard. Hitting time is\nremarkably unlike any of the other nine in its predictions, despite its reasonable performance. The\nnumber of common correct predictions shows qualitatively similar behavior; see Figure 9. It would\ninteresting to understand the generality of these overlap phenomena, especially since certain of the\nlarge overlaps do not seem to follow obviously from the de(cid:12)nitions of the measures.It is harder to quantify the relationships among the datasets, but this is a very interesting issue\nas well. One perspective is provided by the methods based on low-rank approximation: on four\nof the datasets, their performance tends to be best at an intermediate rank, while on gr-qc they\nperform best at rank 1. This suggests a sense in which the collaborations in gr-qc have a much\n\\simpler" structure than in the other four. One also observes the apparent importance of node\ndegree in the hep-ph collaborations: the preferential attachment predictor|which considers only\nthe number (and not the identity) of a scientist s co-authors|does uncharacteristically well on this\ndataset, outperforming the basic graph distance predictor. Finally, it would be interesting to make\nprecise a sense in which astro-ph is a \\di(cid:14)cult" dataset, given the low performance of all methods\nrelative to random, and the fact that none beats simple ranking by common neighbors. We will\nexplore this issue further below when we consider collaboration data drawn from other (cid:12)elds.13\x0cr\na\nd\nA\n/\nc\ni\nm\na\nd\nA92g\nn\ni\nr\ne\nt\ns\nu\nl\ncz\nt\na\nK65\n78s\nr\no\nb\nh\ng\ni\ne\nnn\no\nm\nm\no\nc53\n41\n69e\nmi\ntg\nn\ni\nt\nt\ni\nh22\n20\n13\n40t\nn\ne\ni\nc\n(cid:14)\ne\no\ncs\n \nd\nr\na\nc\nc\na\nJ43\n29\n43\n8\n71z\nt\na\nK\nd\ne\nt\nh\ng\ni\ne\nw87\n66\n52\n22\n41\n92t\nc\nu\nd\no\nr\npr\ne\nn\nn\nik\nn\na\nr\n-\nw\no\nl72\n60\n43\n19\n32\n75\n79k\nn\na\nr\ne\ng\na\nP\nd\ne\nt\no\no\nr44\n31\n27\n17\n39\n44\n39\n69sm\na\nr\ng\ni\nbn\ne\ne\ns\nn\nu49\n37\n40\n15\n43\n51\n46\n39\n34\n68k\nn\na\nR\nm\ni\nS36\n22\n26\n9\n51\n32\n26\n48\n66Adamic/Adar\nKatz clustering\ncommon neighbors\nhitting time\nJaccard s coe(cid:14)cient\nweighted Katz\nlow-rank inner product\nrooted Pagerank\nSimRank\nunseen bigramsFigure 9: The number of correct common predictions made by various predictors on the cond-mat\ndataset, out of 1150 predictions. The diagonal entries indicate the number of correct predictions\nfor each predictor. Parameter settings are as in Figure 5.It is reassuring that even the basic graph distance predictor handily outperforms\nSmall worlds.\nrandom predictions, but this measure has severe limitations. Extensive research has been devoted\nto understanding the so-called small world problem in collaboration networks|i.e., accounting for\nthe existence of short paths connecting virtually every pair of scientists [18]. This property is\nnormally viewed as a vital fact about the scienti(cid:12)c community (new ideas spread quickly, and every\ndiscipline interacts with and gains from other (cid:12)elds) but in the context of our prediction task, we\ncome to a di(cid:11)erent conclusion: the small world problem is really a problem. The shortest path\nbetween two scientists in wholly unrelated disciplines is often very short (and very tenuous). To\ntake one particular (but not atypical) example, the developmental psychologist Jean Piaget has as\nsmall an Erd(cid:127)os Number|three [4]|as most mathematicians and computer scientists. Overall, the\nbasic graph distance predictor is not competitive with most of the other approaches studied; our\nmost successful link predictors can be viewed as using measures of proximity that are robust to the\nfew edges that result from rare collaborations between (cid:12)elds.Restricting to distance three. The small world problem suggests that there are many pairs\nwith graph distance two that will not collaborate, but we also observe the dual problem: many\npairs that collaborate are at distance larger than two. Between 71% (hep-ph) and 83% (cond-mat)\nof new edges form between pairs at distance three or greater; see Figure 10.Since most new collaborations are not at distance two, we are also interested in how well our\npredictors perform when we disregard all distance-two pairs. Clearly, nodes at distance greater than\ntwo have no neighbors in common, and hence this task essentially rules out the use of methods based\non common neighbors. The performance of the other measures is shown in Figure 11. The graph14\x0c# pairs at distance two\n# new collaborations at distance two\n# new collaborationsastro-ph\n33862\n1533\n5751cond-mat\n5145\n190\n1150gr-qc\n935\n68\n400hep-ph\n37687\n945\n3294hep-th\n7545\n335\n1576Figure 10: Relationship between new collaborations and graph distance.distance predictor (i.e., predicting all distance-three pairs) performs between three and eight times\nrandom, and is consistently beaten by virtually all of the predictors: SimRank, rooted PageRank,\nKatz, and the low-rank approximation and unseen bigram techniques. The unweighted Katz and\nunseen bigram predictors have the best performance (as high as about 30 times random, on gr-qc),\nfollowed closely by weighted Katz, SimRank, and rooted PageRank.The breadth of the data. We also have considered three other datasets: (1) the proceedings of\nthe theoretical computer science conferences Symposium on the Theory of Computing (STOC) and\nFoundations of Computer Science (FOCS), (2) the papers found in the Citeseer (www.citeseer.\ncom) online database, which (cid:12)nds papers by crawling the web for any (cid:12)les in postscript form, and\n(3) all (cid:12)ve of the arXiv sections merged into one. Consider the performance of the common neighbor\npredictor versus random on these datasets:STOC/FOCSarXiv sectionsall arXiv s Citeseer6.118.0|41.171.2147.0Performance versus random swells dramatically as the topical focus of our data set widens. That\nis, when we consider a more diverse collection of scientists, it is fundamentally easier to group\nscientists into (cid:12)elds of study (and outperform random predictions, which will usually make guesses\nbetween (cid:12)elds). When we consider a su(cid:14)ciently narrow set of researchers|e.g., STOC/FOCS|\nalmost any author can collaborate with almost any other author, and there seems to a strong\nrandom component to new collaborations. (In extensive experiments on the STOC/FOCS data,\nwe could not beat random guessing by a factor of more than about seven.) It is an interesting\nchallenge to formalize the sense in which the STOC/FOCS collaborations are truly intractable to\npredict|i.e., to what extent information about new collaborations is simply not present in the old\ncollaboration data.Future directions. While the predictors we have discussed perform reasonably well, even the\nbest (Katz clustering on gr-qc) is correct on only about 16% of its predictions. There is clearly much\nroom for improvement in performance on this task, and (cid:12)nding ways to take better advantage of\nthe information in the training data is an interesting open question. Another issue is to improve the\ne(cid:14)ciency of the proximity-based methods on very large networks; fast algorithms for approximating\nthe distribution of node-to-node distances may be one approach [21].The graph Gcollab is a lossy representation of the data; we can also consider a bipartite col-\nlaboration graph Bcollab , with a vertex for every author and paper, and an edge connecting each\npaper to each of its authors. The bipartite graph contains more information than Gcollab , so we\nmay hope that predictors can use it to improve performance. The size of Bcollab is much larger\nthan Gcollab , making experiments prohibitive, but we have tried using the SimRank and Katz pre-\ndictors on smaller datasets (gr-qc, or shorter training periods). Their performance does not seem\nto improve, but perhaps other predictors can fruitfully exploit the additional information in Bcollab .15\x0cpredictorastro-phcond-matgr-qchep-phhep-th(cid:13) = 0:83.1\n3.2\n6.0\n4.4\n2.0\n4.0\n2.6\n4.6\n5.4\n5.4\n5.9\n6.4\n1.5\n5.8\n6.3\n2.4\n9.2\n9.3\n2.3\n4.8\n3.9\n5.4\n5.4\n6.1\n4.1\n3.8\n3.0\n4.6\n5.2\n6.1\n4.3\n3.6\n2.9\n5.1\n5.5\n0.3\n5.8\n7.9\n5.2\n6.6\n5.6\n6.4\n4.2\n4.3\n3.5\n4.8\n2.5\n2.15.5\n2.6\n14.4\n10.2\n2.5\n5.9\n0.8\n12.7\n13.6\n11.9\n13.6\n15.2\n5.9\n14.4\n13.6\n12.7\n11.9\n11.9\n2.5\n5.9\n12.7\n6.8\n6.8\n2.5\n6.8\n8.5\n11.9\n8.5\n6.8\n2.5\n6.8\n8.5\n11.9\n8.5\n6.8\n2.5\n6.8\n9.3\n10.2\n10.2\n5.1\n8.5\n7.6\n4.2\n4.2\n4.2\n5.9\n11.98.4\n8.6\n10.6\n13.7\n0.0\n21.1\n1.1\n21.1\n21.1\n18.0\n8.5\n7.4\n11.6\n28.5\n27.5\n30.6\n30.6\n30.6\n9.5\n5.3\n5.3\n6.3\n32.8\n32.8\n6.3\n3.2\n2.1\n4.2\n27.5\n32.8\n28.5\n3.2\n2.1\n5.3\n28.5\n32.8\n14.8\n28.5\n22.2\n29.6\n13.7\n25.4\n22.2\n28.5\n31.7\n32.8\n7.4\n6.33.8\n4.7\n7.7\n4.5\n2.6\n6.0\n4.8\n6.5\n8.8\n11.1\n11.9\n13.1\n2.3\n4.3\n4.3\n9.1\n5.1\n5.1\n4.0\n10.2\n7.1\n6.8\n2.0\n4.3\n6.2\n8.5\n4.0\n6.0\n2.0\n4.3\n6.2\n8.5\n4.3\n6.0\n2.0\n4.3\n4.3\n5.1\n2.8\n3.7\n4.5\n4.8\n2.0\n3.1\n7.1\n7.7\n4.5\n6.88.4\n1.4\n22.0\n4.7\n6.7\n6.7\n4.7\n12.7\n16.6\n20.0\n20.0\n20.0\n2.7\n12.7\n12.7\n12.7\n18.0\n18.0\n6.0\n10.7\n11.3\n15.3\n4.7\n8.0\n13.3\n20.0\n10.0\n16.6\n4.7\n8.0\n13.3\n20.6\n10.7\n16.0\n4.7\n8.0\n24.0\n19.3\n18.0\n15.3\n21.3\n22.0\n17.3\n16.6\n8.7\n6.7\n8.0\n5.3Katz (weighted)Katz (unweighted)Low-rank approximation:\nInner productgraph distance (all distance-three pairs)\npreferential attachment\nSimRank\nhitting time\nhitting time|normed by stationary distribution\ncommute time\ncommute time|normed by stationary distribution\n(cid:11) = 0:01\nrooted PageRank\n(cid:11) = 0:05\n(cid:11) = 0:15\n(cid:11) = 0:30\n(cid:11) = 0:50\n(cid:12) = 0:05\n(cid:12) = 0:005\n(cid:12) = 0:0005\n(cid:12) = 0:05\n(cid:12) = 0:005\n(cid:12) = 0:0005\nrank = 1024\nrank = 256\nrank = 64\nrank = 16\nrank = 4\nrank = 1\nrank = 1024\nrank = 256\nrank = 64\nrank = 16\nrank = 4\nrank = 1\nrank = 1024\nrank = 256\nrank = 64\nrank = 16\nrank = 4\nrank = 1\ncommon neighbors, (cid:14) = 8\ncommon neighbors, (cid:14) = 16\nKatz ((cid:12) = 0:005), (cid:14) = 8\nKatz ((cid:12) = 0:005), (cid:14) = 16\ncommon neighbors, (cid:14) = 8\ncommon neighbors, (cid:14) = 16\nKatz ((cid:12) = 0:005), (cid:14) = 8\nKatz ((cid:12) = 0:005), (cid:14) = 16\n(cid:26) = 0:10\n(cid:26) = 0:15\n(cid:26) = 0:20\n(cid:26) = 0:25clustering:\nKatz ((cid:12)1 = 0:001; (cid:12)2 = 0:1)unseen bigrams\n(weighted)unseen bigrams\n(unweighted)Low-rank approximation:\nMatrix entryLow-rank approximation:\nKatz ((cid:12) = 0:005)Figure 11: The Distance-3 Task: performance of predictors only on edges in Enew for which the\nendpoints were at distance three or more in Gcollab . Methods based on common neighbors are not\nappropriate for this task. See Section 4.16\x0cSimilarly, our experiments treat all training period collaborations equally. Perhaps one can\nimprove performance by treating more recent collaborations as more important than older ones.\nOne could also tune the parameters of the Katz predictor, e.g., by dividing the training set into\ntemporal segments, training (cid:12) on the beginning, and then using the end of the training set to make\n(cid:12)nal predictions.Finally, there has been relevant work in the machine learning community on estimating distribu-\ntion support: given samples from an unknown probability distribution P , we must (cid:12)nd a \\simple"\nset S so that Prx(cid:24)P [x =2 S] < " [25]. We can view training period collaborations as samples drawn\nfrom a probability distribution on pairs of scientists; our goal is to approximate the set of pairs\nthat have positive probability of collaborating. It is an open question whether these techniques can\nbe fruitfully applied to the link prediction problem.Acknowledgements. We thank Jon Herzog, Tommi Jaakkola, Lillian Lee, Frank McSherry, and\nGrant Wang for helpful discussions and comments on earlier drafts of this paper. We thank Paul\nGinsparg for generously providing the bibliographic data from the arXiv.References[1] Lada A. Adamic and Eytan Adar. Friends and neighbors on the web. Social Networks,25(3):211{230, July 2003.[2] A. L. Barabasi, H. Jeong, Z. N(cid:19)eda, E. Ravasz, A. Schubert, and T. Vicsek. Evolution of thesocial network of scienti(cid:12)c collaboration. Physica A, 311(3{4):590{614, 2002.[3] Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine.Computer Networks and ISDN Systems, 30(1{7):107{117, 1998.[4] Rodrigo De Castro and Jerrold W. Grossman. Famous trails to Paul Erd(cid:127)os. MathematicalIntelligencer, 21(3):51{63, 1999.[5] J(cid:127)orn Davidsen, Holger Ebel, and Stefan Bornholdt. Emergence of a small world from localinteractions: Modeling acquaintance networks. Physical Review Letters, 88(128701), 2002.[6] Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, and Richard\nHarshman. Indexing by latent semantic analysis. Journal of the American Society for Infor-\nmation Science, 41(6):391{407, 1990.[7] Ute Essen and Volker Steinbiss. Cooccurrence smoothing for stochastic language modeling. In\nProceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing,\nvolume 1, pages 161{164, 1992.[8] Debra S. Goldberg and Frederick P. Roth. Assessing experimentally derived interactions in\na small world. In Proceedings of the National Academy of Sciences USA, volume 100, pages\n4372{4376, April 2003.[9] Jerrold W. Grossman. The evolution of the mathematical research collaboration graph. In\nProceedings of the Southeast Conference on Combinatorics, Graph Theory, and Computing,\nMarch 2002.17\x0c[10] Glen Jeh and Jennifer Widom. SimRank: A measure of structural-context similarity.In\nProceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data\nMining, July 2002.[11] Emily M. Jin, Michelle Girvan, and M. E. J. Newman. The structure of growing social networks.Physical Review Letters E, 64(046132), 2001.[12] Leo Katz. A new status index derived from sociometric analysis. Psychometrika, 18(1):39{43,March 1953.[13] H. Kautz, B. Selman, and M. Shah. ReferralWeb: Combining social networks and collaborative(cid:12)ltering. Communications of the ACM, 30(3), March 1997.[14] Valdis Krebs. Mapping networks of terrorist cells. Connections, 24(3):43{52, Winter 2002.[15] Lillian Lee. Measures of distributional similarity. In Proceedings of the Annual Meeting of theAssociation for Computational Linguistics, pages 25{32, 1999.[16] Michael Mitzenmacher. A brief history of lognormal and power law distributions. In Proceed-\nings of the Allerton Conference on Communication, Control, and Computing, pages 182{191,\n2001.[17] M. E. J. Newman. Clustering and preferential attachment in growing networks. PhysicalReview Letters E, 64(025102), 2001.[18] M. E. J. Newman. The structure of scienti(cid:12)c collaboration networks. Proceedings of theNational Academy of Sciences USA, 98:404{409, 2001.[19] M. E. J. Newman. The structure and function of networks. Computer Physics Communications,147:40{45, 2002.[20] M. E. J. Newman. The structure and function of complex networks. SIAM Review, 45:167{256,2003.[21] Christopher Palmer, Phillip Gibbons, and Christos Faloutsos. ANF: A fast and scalable tool for\ndata mining in massive graphs. In Proceedings of the ACM SIGKDD International Conference\non Knowledge Discovery and Data Mining, Jul 2002.[22] A. Popescul and L. Ungar. Statistical relational learning for link prediction. In Workshop\non Learning Statistical Models from Relational Data at the International Joint Conference on\nArti(cid:12)cial Intelligence, 2003.[23] P. Raghavan. Social networks: From the web to the enterprise. IEEE Internet Computing,6(1):91{94, January/February 2002.[24] Gerard Salton and Michael J. McGill. Introduction to Modern Information Retrieval. McGraw-Hill, 1983.[25] Bernhard Sch(cid:127)olkopf, John C. Platt, John Shawe-Taylor, Alex J. Smola, and Robert C.\nWilliamson. Estimating the support of a high-dimensional distribution. Technical Report\nMSR-TR-99-87, Microsoft Research, 1999.18\x0c[26] Ben Taskar, Ming-Fai Wong, Pieter Abbeel, and Daphne Koller. Link prediction in relationaldata. In Proceedings of Neural Information Processing Systems, 2004. To appear.[27] Duncan J. Watts. Small Worlds. Princeton University Press, 1999.[28] Duncan J. Watts and Steven H. Strogatz. Collective dynamics of  small-world  networks.Nature, 393:440{442, 1998.19\x0c'